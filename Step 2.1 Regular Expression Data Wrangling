# Now that we have collected some raw datasets from several sources, we need to perform some wrangling
# in order to imporve data quality
#
# Import the required libraries
require("tidyverse")
library(tidyverse)

# For this task we are given some collected files that maintain a sense of consistency across the project
# Download the necessary files or use the files youve already collected

# Download raw_bike_sharing_systems.csv
url <- "https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-RP0321EN-SkillsNetwork/labs/datasets/raw_bike_sharing_systems.csv"
download.file(url, destfile = "raw_bike_sharing_systems.csv")

# Download raw_cities_weather_forecast.csv
url <- "https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-RP0321EN-SkillsNetwork/labs/datasets/raw_cities_weather_forecast.csv"
download.file(url, destfile = "raw_cities_weather_forecast.csv")

# Download raw_worldcities.csv
url <- "https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-RP0321EN-SkillsNetwork/labs/datasets/raw_worldcities.csv"
download.file(url, destfile = "raw_worldcities.csv")

# Download raw_seoul_bike_sharing.csv
url <- "https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-RP0321EN-SkillsNetwork/labs/datasets/raw_seoul_bike_sharing.csv"
download.file(url, destfile = "raw_seoul_bike_sharing.csv")

# We will create a data set list, this will allow us to to normalize columns later
dataset_list <- c('raw_bike_sharing_systems.csv', 'raw_seoul_bike_sharing.csv', 'raw_cities_weather_forecast.csv', 'raw_worldcities.csv')

# Next we will upper case all column names and replace white space with underscores
for (dataset_name in dataset_list){
    dataset <- read_csv(dataset_name)
    names(dataset) <- toupper(names(dataset))
    names(dataset) <- str_replace_all(names(dataset), " ", "_")
    write.csv(dataset, dataset_name, row.names=FALSE)
}

# Now check to see if the changes have been saved 
for (dataset_name in dataset_list){
    dataset <- read_csv(dataset_name)
    print(summary(dataset))
}

# Now that we have normalized the columns of our data set we can begin to process the web-scraped
# bike sharing system dataset

# First load the dataset and print its head
bike_sharing_df <- read_csv("raw_bike_sharing_systems.csv")
head(bike_sharing_df)

# For this project we will only focus on the following columns 'COUNTRY', 'CITY', 'SYSTEM', 'BICYCLES'. 
# You can process the other columns if you would like
# From our data set we will remove the undesirable, embedded textual content, such as the reference links

# Select our four columns and check their class
sub_bike_sharing_df <- bike_sharing_df %>% select(COUNTRY, CITY, SYSTEM, BICYCLES)
sub_bike_sharing_df %>% 
    summarize_all(class) %>%
    gather(variable, class)

# Now lets evaluate why our 'BICYCLES' column isnt of type numeric like we expect
# This function will take an a column for input and locate and return all values that inlcude a non-numric character
find_character <- function(strings) grepl("[^0-9]", strings)

# Run the function on the data frame
sub_bike_sharing_df %>% 
    select(BICYCLES) %>% 
    filter(find_character(BICYCLES)) %>%
    slice(0:10)
    
# You will notice that many rows incluce non-numeric characters, and we'll clean this up later, for now lets
# look at the other columns in our subset

#For this we create a new function that looks for any character wrapped in a square bracket
ref_pattern <- "\\[[A-z0-9]+\\]"
find_reference_pattern <- function(strings) grepl(ref_pattern, strings)

# Now we check the other three columns
sub_bike_sharing_df %>% 
    select(COUNTRY) %>% 
    filter(find_reference_pattern(COUNTRY)) %>%
    slice(0:10)
    
sub_bike_sharing_df %>% 
    select(CITY) %>% 
    filter(find_reference_pattern(CITY)) %>%
    slice(0:10)
    
sub_bike_sharing_df %>% 
    select(SYSTEM) %>% 
    filter(find_reference_pattern(SYSTEM)) %>%
    slice(0:10)
    
# we can see that 'COUNTRY' is clean, while the 'CITY' and 'SYSTEM' need to be cleaned

# Now we can remove undesired reference links using regular expressions 
# First we define a function to do the heavy lifting
remove_ref <- function(strings) {
    result <- str_replace_all(strings,"\\[[A-z0-9]+\\]","")
    result <- str_squish(strings)
    # Trim the reslt if you want
    return(result)
}

# Next we mutate the columns in the data frame passing the columns into the the function we just defined
result <- sub_bike_sharing_df %>%
mutate(COUNTRY=remove_ref(COUNTRY),
       CITY=remove_ref(CITY),
       SYSTEM=remove_ref(SYSTEM),
       BICYCLES=remove_ref(BICYCLES))

# Now check our columns to make sure all reference links are removed
result %>% 
    select(CITY, SYSTEM, BICYCLES) %>% 
    filter(find_reference_pattern(CITY) | find_reference_pattern(SYSTEM) | find_reference_pattern(BICYCLES))

# The next step is to extract the numeric values from our 'BICYCLES' column and convert the values to numeric
extract_num <- function(columns){
    result <- str_extract(columns,"[0-9]+")
    result <- as.numeric(result)
    return(result)
}

# Now mutate the 'BICYCLES' to extract and reassign the values then print the results 
result <- result %>%
mutate(BICYCLES=extract_num(BICYCLES))
result

# Now we can use the summary function to check the descriptive statistics of the 'BICYCLES' column
summary(result$BICYCLES)

# Now the last step is to remove the 'NA' values from our data set
# first count the number of na values
sum(is.na(result))

# Now drop the na values and assign the new data frame to a new variable and check its na values
cleaned_data <- drop_na(result)
sum(is.na(cleaned_data))

# You can also print a summary of the new data frame
summary(cleaned_data)

# Now save the cleaned data frame
write.csv(cleaned_data, "bike_sharing_systems.csv", row.index=False)
